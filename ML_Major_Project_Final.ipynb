{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of ML Major Project Final.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RutwikBorkar/TASK1/blob/main/ML_Major_Project_Final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mbi2Lw0Szrpk"
      },
      "source": [
        "Rutwik Borkar"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9CwzisuSz0j1"
      },
      "source": [
        "Machine Learning September Batch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jLROu1I_r7y5"
      },
      "source": [
        "**Machine Learning Major Project**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DOQd7tHosEDt"
      },
      "source": [
        "**Sentiment Analysis for Restaurant Reviews**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Pnq44GisTIC"
      },
      "source": [
        "There are two features -'review' - the sentence and 'sentiment' - the label for the review. 1 means positive review and 0 means negative review"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Yd5W0jnJ9wG"
      },
      "source": [
        "# 1. Process the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ckeG38XwKTg_"
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "id": "GtBFCEUzKVR3",
        "outputId": "2caf6fa6-6189-4ffd-bcb8-d12ae0d05bcc"
      },
      "source": [
        "# read the dataset\n",
        "df = pd.read_csv('/content/Restaurant_Reviews.tsv',sep='\\t')\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Review</th>\n",
              "      <th>Liked</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Wow... Loved this place.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Crust is not good.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Not tasty and the texture was just nasty.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Stopped by during the late May bank holiday of...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The selection on the menu was great and so wer...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              Review  Liked\n",
              "0                           Wow... Loved this place.      1\n",
              "1                                 Crust is not good.      0\n",
              "2          Not tasty and the texture was just nasty.      0\n",
              "3  Stopped by during the late May bank holiday of...      1\n",
              "4  The selection on the menu was great and so wer...      1"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Hge__LynC1V",
        "outputId": "deffa393-1ffe-478e-bd9f-2a03df9b5c4b"
      },
      "source": [
        "df.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1000, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        },
        "id": "YDFTkTUBnGV7",
        "outputId": "425d16b7-92f8-4e3b-f909-0f0849226e0e"
      },
      "source": [
        "# we plot a bar graph just to check the count of positive and negative reviews\n",
        "import matplotlib.pyplot as plt\n",
        "df['Liked'].value_counts().plot(kind='bar')\n",
        "df['Liked'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    500\n",
              "0    500\n",
              "Name: Liked, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 4
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gTtBrk6rKeJ0"
      },
      "source": [
        "# Here we take 2 variables which contains the input and output data\n",
        "# x - Input data\n",
        "# y - Output data\n",
        "x = df['Review'] \n",
        "y = df['Liked']  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o6X9u4h2KoYh"
      },
      "source": [
        "# we use train_test_split to split the data\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train,x_test,y_train,y_test = train_test_split(x,y,random_state = 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HJnKpEL7K-Fc",
        "outputId": "4269b9db-7bf2-4b08-ac67-59949c055490"
      },
      "source": [
        "x_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(750,)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KCQl1FrwnSZm",
        "outputId": "7c7edbdc-5f94-45b9-de46-e7dcbdc5af55"
      },
      "source": [
        "x_test.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(250,)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rB3BPP4euX1X"
      },
      "source": [
        "Processing of data is done"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dHgZXF0DnzUz"
      },
      "source": [
        "# 2.Cleaning of data using stemming"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7-aomiq7n4sm",
        "outputId": "dfd714af-e400-470a-b812-cf4e0eec58eb"
      },
      "source": [
        "# we download the stopwords , punkt and wordnet\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ymsb3X-Bn9cg"
      },
      "source": [
        "# stemming for x_train data\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "stemmer = PorterStemmer()\n",
        "x_train_stem = []\n",
        "x_test_stem = []\n",
        "def stemming(review):\n",
        "  review = re.sub('[^a-zA-Z]',' ',review)\n",
        "  review = review.lower()\n",
        "  review = review.split()\n",
        "  review_stem = [stemmer.stem(word) for word in review if not word in stopwords.words('english')]\n",
        "  review_stem = ' '.join(review_stem)\n",
        "  x_train_stem.append(review_stem)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D7FOtWryoLfT",
        "outputId": "b1be2a3d-0f5d-470c-f416-e02fc4eb8d7f"
      },
      "source": [
        "# rand varibale is used just to apply stemming function for x_train data\n",
        "rand = x_train.apply(stemming)\n",
        "x_train_stem[:5]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['overal think would take parent place made similar complaint silent felt',\n",
              " 'chef gener time even came around twice take pictur',\n",
              " 'love pho spring roll oh yummi tri',\n",
              " 'know big deal place back ya',\n",
              " 'scallop dish quit appal valu well']"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jmA09YWtoUUw"
      },
      "source": [
        "# stemming for x_test data\n",
        "def stemming(review):\n",
        "  review = re.sub('[^a-zA-Z]',' ',review)\n",
        "  review = review.lower()\n",
        "  review = review.split()\n",
        "  review_stem = [stemmer.stem(word) for word in review if not word in stopwords.words('english')]\n",
        "  review_stem = ' '.join(review_stem)\n",
        "  x_test_stem.append(review_stem)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9eSrmG93ojzZ",
        "outputId": "2975c3b8-3ef6-400f-f678-c948141f9e41"
      },
      "source": [
        "# rand2 variable is used just to apply stemming function for x_test data\n",
        "rand2 = x_test.apply(stemming)\n",
        "x_test_stem[:5]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['present food aw',\n",
              " 'worst food servic',\n",
              " 'never dine place',\n",
              " 'guess mayb went night disgrac',\n",
              " 'sushi lover avoid place mean']"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J-Hk_2SfvYpR"
      },
      "source": [
        "Cleaning of data is done using stemming"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bBtiHH-qou19"
      },
      "source": [
        "#3. Creating a pipeline with vectorization model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_i6LWxRCo_Yy"
      },
      "source": [
        "# Pipeline with CountceVtorizer and MultinomialNB model\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "text_model = make_pipeline(CountVectorizer(),MultinomialNB()) # pipeline is created"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RJ4btdyEwIL1"
      },
      "source": [
        "Pipeline is created using CountVectorizer and MultinomialNB"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CfioPT4vwg33"
      },
      "source": [
        "# 4. ML algorithm to predict the final sentiment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KMDA0EtTyQdE",
        "outputId": "cd50db2e-af96-4eeb-ca40-afa3a5f84d7f"
      },
      "source": [
        "# we fit the train and test data into the model\n",
        "text_model.fit(x_train_stem,y_train)\n",
        "\n",
        "y_pred = text_model.predict(x_test_stem) # predict the output for test data\n",
        "y_pred"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0,\n",
              "       1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0,\n",
              "       0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0,\n",
              "       1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0,\n",
              "       1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0,\n",
              "       0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1,\n",
              "       0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1,\n",
              "       1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1,\n",
              "       0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1,\n",
              "       0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1,\n",
              "       0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1,\n",
              "       1, 1, 0, 1, 1, 1, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jn_o6C4npucE"
      },
      "source": [
        "# we check the accuracy from accuracy_score\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tsOAAsVBpwtK",
        "outputId": "3a1b4251-3f7b-40c9-ec5e-6c01df82651f"
      },
      "source": [
        "accuracy_score(y_pred,y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.756"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LgskyWr8zA14"
      },
      "source": [
        "Here '0' represents negative review , and '1' represents positive review"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CeWjEQG6pz4y",
        "outputId": "29832cb5-3c07-40b6-ddc6-3e555d7be313"
      },
      "source": [
        "# predict the output for sentence in the dataset\n",
        "text_model.predict(['The fries were great too.'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wtTR79dYxJ3h",
        "outputId": "9da860d8-4990-4dbb-e212-987df73bbbf9"
      },
      "source": [
        "# predict the output for sentence in the dataset\n",
        "text_model.predict(['This place is not worth your time, let alone Vegas.'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k20ADNbLxM4g",
        "outputId": "4f82c3eb-fe92-4ad1-f155-f267de056cdb"
      },
      "source": [
        "# predict the output for sentence which is not in the dataset\n",
        "text_model.predict(['A very good place to visit , and the service is very good to all the customers'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Acuj7JfBxPUG",
        "outputId": "7f28fe27-b579-4792-df72-f1ee3564e334"
      },
      "source": [
        "# predict the output for sentence which is not in the dataset\n",
        "text_model.predict(['This is the worst place i have ever visited , no proper facilities'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IfXFQ6vTxbOx"
      },
      "source": [
        "**Finally the machine predicts the positive and negative reviews.**"
      ]
    }
  ]
}